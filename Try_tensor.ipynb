{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import yaml\n",
    "import shutil\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of GPUs available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of GPUs available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "input_dir = Path('./data/prepared')\n",
    "logs_path = Path('./data/logs')\n",
    "if logs_path.exists():\n",
    "    shutil.rmtree(logs_path)\n",
    "logs_path.mkdir(parents=True)\n",
    "\n",
    "X_train_name = input_dir / 'X_train.csv'\n",
    "y_train_name = input_dir / 'y_train.csv'\n",
    "X_test_name = input_dir / 'X_test.csv'\n",
    "y_test_name = input_dir / 'y_test.csv'\n",
    "\n",
    "X_train = pd.read_csv(X_train_name)\n",
    "y_train = pd.read_csv(y_train_name)\n",
    "X_test = pd.read_csv(X_test_name)\n",
    "y_test = pd.read_csv(y_test_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "25"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "BATCH_SIZE = [32, 64, 128]\n",
    "BUFFER_SIZE = 256\n",
    "LEARNING_RATE = [0.05, 0.1, 0.0025]\n",
    "EPOCHS = 200\n",
    "NUMBER_OF_NEURONS = [256, 128, 256]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class NotNotMyModel(Model):\n",
    "    def __init__(self, n_of_neurons=64):\n",
    "        super(NotNotMyModel, self).__init__()\n",
    "\n",
    "        self.d_in = Dense(25, activation='relu')\n",
    "        self.d_1 = Dense(n_of_neurons, activation = 'relu')\n",
    "        self.d_2 = Dense(n_of_neurons, activation = 'relu')\n",
    "        self.d_3 = Dense(n_of_neurons, activation = 'relu')\n",
    "        self.d_out = Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.d_in(x)\n",
    "        x = self.d_1(x)\n",
    "        x = self.d_2(x)\n",
    "        x = self.d_3(x)\n",
    "        x = self.d_out(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "top_mae = 100\n",
    "top_params = []\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.MeanAbsoluteError(name='train_mae')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.MeanAbsoluteError(name='test_mae')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_log_dirs(params):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    train_log_dir = logs_path / params / 'gradient_tape' / current_time / 'train'\n",
    "    train_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "    test_log_dir = logs_path / params / 'gradient_tape' / current_time / 'test'\n",
    "    test_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "    fit_log_dir = logs_path / params / \"fit\" / datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    fit_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    return train_log_dir, test_log_dir, fit_log_dir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_vector, labels, model, optimizer, loss_object):\n",
    "    with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(input_vector, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(input_vector, labels, model, loss_object):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(input_vector, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params are: BATCH_SIZE=32, LEARNING_RATE=0.05, NUMBER_OF_NEURONS=256\n",
      "WARNING:tensorflow:From /Users/grigoriiott/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1332: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.start` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 20:47:12.167840: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2022-12-19 20:47:12.167847: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 190052384.0, Accuracy: 1531.12353515625, Test Loss: 19963.69140625, Test MAE: 68.697021484375\n",
      "Epoch: 2, Loss: 12137.6767578125, Accuracy: 51.14064407348633, Test Loss: 1942.1239013671875, Test MAE: 38.69796371459961\n",
      "Epoch: 3, Loss: 1477.829833984375, Accuracy: 29.976032257080078, Test Loss: 646.085205078125, Test MAE: 21.04400062561035\n",
      "Epoch: 4, Loss: 318.42828369140625, Accuracy: 12.879393577575684, Test Loss: 194.6702880859375, Test MAE: 9.992147445678711\n",
      "Epoch: 5, Loss: 238.3948211669922, Accuracy: 10.898737907409668, Test Loss: 303.43511962890625, Test MAE: 12.44105052947998\n",
      "Epoch: 6, Loss: 258.8653564453125, Accuracy: 11.194354057312012, Test Loss: 325.6803894042969, Test MAE: 12.312715530395508\n",
      "Epoch: 7, Loss: 220.8506622314453, Accuracy: 10.475004196166992, Test Loss: 164.28378295898438, Test MAE: 8.238277435302734\n",
      "Epoch: 8, Loss: 174.3322296142578, Accuracy: 9.5321044921875, Test Loss: 94.2801284790039, Test MAE: 7.611474990844727\n",
      "Epoch: 9, Loss: 180.42803955078125, Accuracy: 9.223247528076172, Test Loss: 789.041259765625, Test MAE: 21.763093948364258\n",
      "Epoch: 10, Loss: 214.31866455078125, Accuracy: 10.590001106262207, Test Loss: 122.23310089111328, Test MAE: 7.736091613769531\n",
      "Epoch: 11, Loss: 253.10386657714844, Accuracy: 10.41809368133545, Test Loss: 608.8719482421875, Test MAE: 11.385950088500977\n",
      "Epoch: 12, Loss: 353.5408630371094, Accuracy: 11.89837646484375, Test Loss: 272.4339294433594, Test MAE: 10.517253875732422\n",
      "Epoch: 13, Loss: 203.22523498535156, Accuracy: 9.953010559082031, Test Loss: 190.1715087890625, Test MAE: 10.198075294494629\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [13], line 27\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (x_train, y_train) \u001B[38;5;129;01min\u001B[39;00m train_ds:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m fit_summary_writer\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[0;32m---> 27\u001B[0m         \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_object\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m train_summary_writer\u001B[38;5;241m.\u001B[39mas_default():\n\u001B[1;32m     30\u001B[0m     tf\u001B[38;5;241m.\u001B[39msummary\u001B[38;5;241m.\u001B[39mscalar(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m, train_loss\u001B[38;5;241m.\u001B[39mresult(), step\u001B[38;5;241m=\u001B[39mepoch)\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_functions_eagerly:\n\u001B[1;32m    856\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name, tf_function_call\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 857\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[38;5;66;03m# Only count the statistics the first time, before initialization took\u001B[39;00m\n\u001B[1;32m    860\u001B[0m \u001B[38;5;66;03m# place.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn [11], line 9\u001B[0m, in \u001B[0;36mtrain_step\u001B[0;34m(input_vector, labels, model, optimizer, loss_object)\u001B[0m\n\u001B[1;32m      7\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_object(labels, predictions)\n\u001B[1;32m      8\u001B[0m gradients \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(loss, model\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[0;32m----> 9\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgradients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m train_loss(loss)\n\u001B[1;32m     12\u001B[0m train_accuracy(labels, predictions)\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1140\u001B[0m, in \u001B[0;36mOptimizer.apply_gradients\u001B[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001B[0m\n\u001B[1;32m   1138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m skip_gradients_aggregation \u001B[38;5;129;01mand\u001B[39;00m experimental_aggregate_gradients:\n\u001B[1;32m   1139\u001B[0m     grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate_gradients(grads_and_vars)\n\u001B[0;32m-> 1140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:634\u001B[0m, in \u001B[0;36m_BaseOptimizer.apply_gradients\u001B[0;34m(self, grads_and_vars, name)\u001B[0m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_weight_decay(trainable_variables)\n\u001B[1;32m    633\u001B[0m grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(grads, trainable_variables))\n\u001B[0;32m--> 634\u001B[0m iteration \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_apply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    636\u001B[0m \u001B[38;5;66;03m# Apply variable constraints after applying gradients.\u001B[39;00m\n\u001B[1;32m    637\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m variable \u001B[38;5;129;01min\u001B[39;00m trainable_variables:\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1166\u001B[0m, in \u001B[0;36mOptimizer._internal_apply_gradients\u001B[0;34m(self, grads_and_vars)\u001B[0m\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_internal_apply_gradients\u001B[39m(\u001B[38;5;28mself\u001B[39m, grads_and_vars):\n\u001B[0;32m-> 1166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__internal__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_merge_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1167\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_distributed_apply_gradients_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1168\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_distribution_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1170\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001B[0m, in \u001B[0;36mmaybe_merge_call\u001B[0;34m(fn, strategy, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;124;03m  The return value of the `fn` call.\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m strategy_supports_no_merge_call():\n\u001B[0;32m---> 51\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m distribution_strategy_context\u001B[38;5;241m.\u001B[39mget_replica_context()\u001B[38;5;241m.\u001B[39mmerge_call(\n\u001B[1;32m     54\u001B[0m       fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1216\u001B[0m, in \u001B[0;36mOptimizer._distributed_apply_gradients_fn\u001B[0;34m(self, distribution, grads_and_vars, **kwargs)\u001B[0m\n\u001B[1;32m   1213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_step(grad, var)\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m grad, var \u001B[38;5;129;01min\u001B[39;00m grads_and_vars:\n\u001B[0;32m-> 1216\u001B[0m     \u001B[43mdistribution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextended\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapply_grad_to_update_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_ema:\n\u001B[1;32m   1221\u001B[0m     _, var_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mgrads_and_vars)\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001B[0m, in \u001B[0;36mStrategyExtendedV2.update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   2634\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   2635\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   2636\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 2637\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2638\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2639\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_replica_ctx_update(\n\u001B[1;32m   2640\u001B[0m       var, fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs, group\u001B[38;5;241m=\u001B[39mgroup)\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   3707\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update\u001B[39m(\u001B[38;5;28mself\u001B[39m, var, fn, args, kwargs, group):\n\u001B[1;32m   3708\u001B[0m   \u001B[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001B[39;00m\n\u001B[1;32m   3709\u001B[0m   \u001B[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001B[39;00m\n\u001B[0;32m-> 3710\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_non_slot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._update_non_slot\u001B[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001B[0m\n\u001B[1;32m   3712\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_non_slot\u001B[39m(\u001B[38;5;28mself\u001B[39m, colocate_with, fn, args, kwargs, should_group):\n\u001B[1;32m   3713\u001B[0m   \u001B[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001B[39;00m\n\u001B[1;32m   3714\u001B[0m   \u001B[38;5;66;03m# once that value is used for something.\u001B[39;00m\n\u001B[1;32m   3715\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m UpdateContext(colocate_with):\n\u001B[0;32m-> 3716\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3717\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_group:\n\u001B[1;32m   3718\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:595\u001B[0m, in \u001B[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    594\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mControlStatusCtx(status\u001B[38;5;241m=\u001B[39mag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mUNSPECIFIED):\n\u001B[0;32m--> 595\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1213\u001B[0m, in \u001B[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001B[0;34m(var, grad)\u001B[0m\n\u001B[1;32m   1211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_step_xla(grad, var, \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_var_key(var)))\n\u001B[1;32m   1212\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1213\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:224\u001B[0m, in \u001B[0;36m_BaseOptimizer._update_step\u001B[0;34m(self, gradient, variable)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_var_key(variable) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_dict:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe optimizer cannot recognize variable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvariable\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis usually means you are trying to call the optimizer to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.keras.optimizers.legacy.\u001B[39m\u001B[38;5;132;01m{self.__class__.__name__}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    223\u001B[0m     )\n\u001B[0;32m--> 224\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariable\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/adam.py:170\u001B[0m, in \u001B[0;36mAdam.update_step\u001B[0;34m(self, gradient, variable)\u001B[0m\n\u001B[1;32m    167\u001B[0m m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_momentums[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_dict[var_key]]\n\u001B[1;32m    168\u001B[0m v \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_velocities[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_dict[var_key]]\n\u001B[0;32m--> 170\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[43mlr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbeta_2_power\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta_1_power)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(gradient, tf\u001B[38;5;241m.\u001B[39mIndexedSlices):\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m# Sparse gradients.\u001B[39;00m\n\u001B[1;32m    174\u001B[0m     m\u001B[38;5;241m.\u001B[39massign_add(\u001B[38;5;241m-\u001B[39mm \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta_1))\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:1090\u001B[0m, in \u001B[0;36mVariable._OverloadOperator.<locals>._run_op\u001B[0;34m(a, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1088\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_op\u001B[39m(a, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1089\u001B[0m   \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m-> 1090\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m tensor_oper(\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:584\u001B[0m, in \u001B[0;36mBaseResourceVariable.value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    582\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_value\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28;01mNone\u001B[39;00m, ignore_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 584\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_variable_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:706\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op\u001B[0;34m(self, no_copy)\u001B[0m\n\u001B[1;32m    704\u001B[0m       result \u001B[38;5;241m=\u001B[39m read_and_set_handle(no_copy)\n\u001B[1;32m    705\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 706\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mread_and_set_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mno_copy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m    709\u001B[0m   \u001B[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001B[39;00m\n\u001B[1;32m    710\u001B[0m   \u001B[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001B[39;00m\n\u001B[1;32m    711\u001B[0m   tape\u001B[38;5;241m.\u001B[39mrecord_operation(\n\u001B[1;32m    712\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReadVariableOp\u001B[39m\u001B[38;5;124m\"\u001B[39m, [result], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle],\n\u001B[1;32m    713\u001B[0m       backward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x],\n\u001B[1;32m    714\u001B[0m       forward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x])\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:696\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001B[0;34m(no_copy)\u001B[0m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m no_copy \u001B[38;5;129;01mand\u001B[39;00m forward_compat\u001B[38;5;241m.\u001B[39mforward_compatible(\u001B[38;5;241m2022\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m    695\u001B[0m   gen_resource_variable_ops\u001B[38;5;241m.\u001B[39mdisable_copy_on_read(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle)\n\u001B[0;32m--> 696\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mgen_resource_variable_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_variable_op\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    698\u001B[0m _maybe_set_handle_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dtype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, result)\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Documents/TPU/Семак 7/NN/LinearRegression/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:525\u001B[0m, in \u001B[0;36mread_variable_op\u001B[0;34m(resource, dtype, name)\u001B[0m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m    524\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 525\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mReadVariableOp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdtype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m    528\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for batch in BATCH_SIZE:\n",
    "    #print(batch)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (pd.read_csv(X_train_name), pd.read_csv(y_train_name))\n",
    "    ).shuffle(BUFFER_SIZE).batch(batch)\n",
    "\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (pd.read_csv(X_test_name), pd.read_csv(y_test_name))\n",
    "    ).batch(batch)\n",
    "    for lr in LEARNING_RATE:\n",
    "        #optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        for n_neurons in NUMBER_OF_NEURONS:\n",
    "            params = 'ba{}_lr{}_nn{}'.format(batch, lr, n_neurons)\n",
    "            train_log_dir, test_log_dir, logdir= get_log_dirs(params)\n",
    "            train_summary_writer = tf.summary.create_file_writer(str(train_log_dir))\n",
    "            test_summary_writer = tf.summary.create_file_writer(str(test_log_dir))\n",
    "            fit_summary_writer = tf.summary.create_file_writer(str(logdir))\n",
    "            print(\"Params are: BATCH_SIZE={}, LEARNING_RATE={}, NUMBER_OF_NEURONS={}\".format(batch, lr, n_neurons))\n",
    "            tf.summary.trace_on(graph=True, profiler=True)\n",
    "            model = NotNotMyModel(n_of_neurons=n_neurons)\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            #print(getattr(model, 'x'))\n",
    "\n",
    "            for epoch in range(EPOCHS):\n",
    "                for (x_train, y_train) in train_ds:\n",
    "                    with fit_summary_writer.as_default():\n",
    "                        train_step(x_train, y_train, model, optimizer, loss_object)\n",
    "\n",
    "                with train_summary_writer.as_default():\n",
    "                    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "                    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "                for (x_test, y_test) in test_ds:\n",
    "                    test_step(x_test, y_test, model, loss_object)\n",
    "\n",
    "                with test_summary_writer.as_default():\n",
    "                    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "                    tf.summary.scalar('mae', test_accuracy.result(), step=epoch)\n",
    "\n",
    "                template = 'Epoch: {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test MAE: {}'\n",
    "                print (template.format(epoch+1,\n",
    "                                       train_loss.result(),\n",
    "                                       train_accuracy.result(),\n",
    "                                       test_loss.result(),\n",
    "                                       test_accuracy.result()))\n",
    "                if epoch+1 == EPOCHS:\n",
    "                    if top_mae > test_accuracy.result():\n",
    "                        top_params = [batch, lr, n_neurons]\n",
    "                        top_mae = test_accuracy.result()\n",
    "                        model.save('data/models/MyNN', overwrite=True)\n",
    "\n",
    "                train_loss.reset_states()\n",
    "                train_accuracy.reset_states()\n",
    "                test_loss.reset_states()\n",
    "                test_accuracy.reset_states()\n",
    "\n",
    "            with fit_summary_writer.as_default():\n",
    "                tf.summary.trace_export(\n",
    "                    name = \"my_func_trace\",\n",
    "                    step=0,\n",
    "                    profiler_outdir=logdir\n",
    "                )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(top_params)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
